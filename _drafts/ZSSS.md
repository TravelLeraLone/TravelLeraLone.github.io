---
layout: post
title: 再读Zero-Shot Semantic Segmentation
tags: Notes SS NetStruc ZSL
categories: Paper
excerpt: 与个人研究方向相关的一篇文章，相对粗糙，但作为第一个做这个方向的也已经很不容易了
---

**原文链接：[Zero-Shot Semantic Segmentation](https://github.com/RohanDoshi2018/ZeroshotSemanticSegmentation)**


# 再读Zero-Shot Semantic Segmentation



## 摘要

本文提出了一个新的任务：零示例语义分割——为每一个像素点分配一个已见类别或未见类别的标签~~（更确切的说是泛化零示例语义分割）~~。为了完成这一目标，本文提出了“可见性覆膜零示例网络”，它可以在像素级别在公共嵌入的空间内联结编码过的视觉和语义嵌入对。其中“可见性覆膜”是用来判断一个给定的像素属于已见类别还是未见类别。本文的结果可以进一步解释在上文提到的联结过程中高密度的类别对于正确率的重要性。另外，本文还通过设定理想的可见性覆膜~~（就是人工标记可见与未见，这种研究方法还是十分有趣的）~~来研究了这种方法的上限。



## 引入

通常，我们的计算机视觉网络是在一些固定的常见类别的标记数据集上进行训练的。由于在一个开放的词库中标记图片是昂贵且不现实的，故而这些类别一定是有限的，于是大多数的事物其实在这个数据集中的捕捉和代表性是很差甚至压根没有的。于是这就激励了对于能识别未见类别的视觉系统的研究。而对于这种零示例学习的研究，很多领先水平的研究都是在试图模仿人类在这个问题上的处理方法——通过转移我们对于其他域内的相似物体或概念的理解来学习或预测未见物体的特点（identity），而这样的尝试，通过从语言领域做转移学习，在图像级别上已经取得了一定的成功。然而在像素级别上的研究却仍然几乎没有。

前人的零示例学习的工作已经提出了在公共嵌入空间中联结图像和标签对的方法：视觉和语义模型被训练来尽量将图像和语义对映射到公共嵌入空间中的一个点上。所以解决本文的问题的一个方法就是将这样的视觉模型从图像级别拓展到像素级别，于是其中的主要问题就是怎样发展一个输出像素级别的嵌入，并且同时要考虑到充足的区域性和全局性图像信息的视觉模型。

另外，还有一个待解决的问题是：视觉模型中在公共嵌入空间中的已见类别的标签和图像的联结应该在怎样的程度上泛化到未见类别中，如果这样的转移越弱，那么整个模型就会越倾向于简单的将所有像素的类别映射到公共嵌入空间中已见类别的区域中。~~（以上直译，好拗口哦...大致作者想表达的意思应该是一个像素应该怎样才会被判定为未见类别，这是泛化零示例学习一定会面对的问题，因为相对于未见类别，已见类别一定是过拟合的，所以最朴素的解决方案便是要设定一个阈值来判定一个对象是否属于已见类别，而这个阈值不合适便会引起将未见类别分为可见类别或反之的误分类）~~  一个可行的解决方法是提前判断一个像素是否在训练阶段“见过”。于是本文的第二个关键便是构建能在像素级别完成这个任务的“可见性覆膜”。

总结来讲，本文的两个关键创新点如下：

 	1. 定义了一个新的任务：零示例语义分割
 	2. 提出了解决这个问题的第一个尝试：带可见性覆膜的零示例网络（SZN）



## 背景和相关工作

### 语义分割

这是现在计算机视觉的一个主要领域之一，FCN现在在这个领域特别成功，本文就使用了FCN作为视觉模型来生成像素级别的视觉嵌入。~~（其实FCN也可以分为两大类，一类是编码解码+跳跃链接型的，另一类是以DeepLab为代表的带孔卷积方法，而本文实际上采用的是两者的共同前身：最基础的啥都没有的FCN）~~

### 零示例学习

零示例学习中的领先的方法是创建一个公共嵌入空间来联结图像-标签对的视觉和语义嵌入信息。以DeViSe为例说明零示例学习的基本过程和损失方程：TODO



## 任务的提出：零示例语义分割

本文采用的数学记号如下：

- 一个图片/图像$$I$$

- 可见类别集合$$S$$

- 不相交的未见类别集合$$U$$

于是在测试阶段，有：


$$
I_{i,j} \in S \cup U
$$



## 带可见性覆膜的零示例网络的提出

### 预测过程总览

简单来讲，这个网络将像素映射到一个公共嵌入空间，并且选择一个附近的已见和未见类别的标签。其中可见性覆膜起到为每一个像素从选出的可见和未见两个类别标签中选择一个的作用。具体的讲，本文将预测过程分为了三个步骤：视觉模型、语义模型、可见性覆膜嵌入预测。

![ZSSS]({{ "/ZSSS.png" | prepend: site.imgrepo }})

### 视觉模型

目标是通过FCN的两个输出接头从$I​$中生成一个视觉嵌入和一个可见性覆膜：

1. FCN：使用32倍下采样的网络（$4096 \times \lceil \frac{h}{32}\rceil \times \lceil \frac w {32} \rceil$）
2. 视觉嵌入接头：本文通过在FCN的输出上使用一个$1\times1$的卷积层并输出$j$个通道（$j$是公共嵌入空间的维度）随后通过用双线性插值初始化的反卷积层上采样32倍，生成一个$j \times h \times w​$的输出，作为像素级别的在公共嵌入空间中的视觉嵌入。
3. 可见性覆膜接头：本文想要生成一个二元的可见性覆膜，其中值为1表示该像素属于一个已见类别，0表示属于一个未见类别。这种覆膜的实现方式如下：在FCN的输出上使用一个$1\times1$的卷积层并输出2个通道随后同样方式上采样32倍得到一个像素级别的可见性覆膜的置信度，最终使用一个像素级别的argmax操作来产生二元判断。

~~（为啥在上采样之前做这个？？？）~~

### 语义模型

语义模型的工作是将$S和U$中的类别标签映射到公共嵌入空间中的语义嵌入中去。这样的工作是通过使用一个在训练阶段生成的语义嵌入查询完成的，具体实现将在下一章中详细介绍。

### 可见性覆膜的嵌入预测

这个过程的目标是最终为每个像素分配一个已见或未见的类别标签，而这是通过以下三步来完成的：

1. 对于每个像素，计算它们的视觉嵌入和每个已见类别的语义嵌入的余弦相似度，选择得分最高的作为其已见类别预测；
2. 同理生成其未见类别预测；
3. 考察该像素的可见性覆膜的值，如果该值为1，则选择已见类别预测作为其最终标签，如果为0，则选择未见类别预测；最终将所有像素的标签缝合到一起就生成了对于整张图片的语义分割图。



## 实际应用

### 训练阶段总览

两步训练：1. 训练FCN和视觉嵌入接头；2. 训练可见性覆膜接头

![ZSSSt]({{ "/ZSSSt.png" | prepend: site.imgrepo }})

#### 预处理：训练类别的拆分

可见性覆膜接头的训练是需要获取到未见类别的，但是一般情况下在训练阶段我们不应该能够获取到未见类别（即测试阶段）的相关信息，于是我们需要进一步的将已见类别$S​$拆分为不相交的$train_{seen}​$和$train_{unseen}​$两个集合。在训练阶段，FCN和视觉嵌入接头仅仅使用整张图片上的类别标签全部存在于$train_{seen}​$内的图片进行训练，而可见性覆膜接头则使用所有训练集图片进行训练，其中随机选择的$train_{unseen}​$类别第用来模拟一个对于真实世界中的未见类别$U​$的随机取样，来帮助可见性覆膜来分辨出已见类别（即$train_{seen}​$）和未见类别（即$train_{unseen}​$和$U​$）。

此外，这样最还有一个需要注意的问题，就是在测试阶段，未见类别标签集合不再是$U$，而需要被扩展为$U \cup train_{unseen}$

#### 对FCN和视觉嵌入模型的训练

用$train_{seen}$集合内的数据对上图中粉色的部分进行训练，对于相关的像素-标签对，本文对他们在公共嵌入空间中的视觉和语义嵌入用一个像素级别的余弦损失进行联结（具体公式见后文），并使用Adam优化器进行优化，每批1张~~（其实是因为本文未做resize，而做过之后会发现性能有极大的下降）~~训练30轮，lr为1e-5，公共嵌入空间维度为$j=20$。

#### 可见性覆膜的训练

随后本文固定FCN中的权重并且将FCN视作一个密集特征图的提取器来作为可见性覆膜接头的输入。于是我们用一个像素级别的二元交叉熵损失训练可见性覆膜接头（其中预测值和真实值分别为$\widehat M_{i,j}, \overline M_{i,j} \in \{0, 1\}$）:


$$
L(\widehat M, \overline M) = \sum_{i,j \in M} -(\overline M_{i,j} \log(\widehat M_{i,j}) +(1-\overline M_{i,j})\log(1-\widehat M_{i,j}))
$$


### 视觉模型

基于VGG-16的FCN~~，并未进行跳跃链接优化或带孔卷积优化~~。

### 语义模型

本文采用了一个在谷歌新闻语料库预训练的Word2Vec模型先将3百万的常用象征词（tokens）嵌入到300维空间中，再用PCA将其降维到$j$维的公共嵌入空间中。

### 公共嵌入损失

本文尝试了两种损失函数：均方根损失和余弦损失。记视觉嵌入向量为$v$、语义嵌入向量为$s$，则均方根损失为：


$$
L(v,s)=\frac 1 {||I||} \sum_{i,j \in I} ||v_{i,j}-s{i,j}||^2
$$


其中，有$||s_{i,j}||\leq1$，因为本文对所有的语义嵌入向量进行了归一化（实际为除了所有向量中最大的模值）；而余弦损失为：


$$
L(v,x)=\frac 1 {||I||} \sum_{i,j\in I}1-sim(v_{i,j},s_{i,j})
$$


其中，$sim(x,y) = \frac {x \cdot y} {||x||\cdot||y||} \in [-1,1]$。

### 代码细节



## 评价方法

~~总感觉这一章的组织很混乱，我想作者应该是想在这一章中将训练测试前的一些其他细节交代清楚，包括使用的数据库、评价方法、参与对比的各个网络结构等，所以个人认为更好的章标题应该是“测试预备工作”~~

### 数据库

本文共使用了两个数据库： PASCAL VOC 和 PADCAL-Context。其中后者是对前者的一个扩充和细化，而本文预测后者会更难训练，因为他有更高的种类密度、更复杂的物体取向和相对更小的数据集大小。

### 评价矩阵

见 [原始FCN](https://travelleralone.github.io/2019-03-10/FCN/) 中的结果一栏中的四个评价数值。

### 模型总览

这节中作者介绍了本文用来进行对比的各个网络结构：

- **FCN+Softmax (FCN-S) **传统语义分割的基础模型，FCN网络后跟一个像素级别的Softmax分类器，并不能用来做零示例的工作，仅仅作为一个基线模型来判断可见性覆膜是否在正常工作。
- **FCN+Joint Embeddings (FCN-JE) **相当于本文提出的模型去掉可见性覆膜，将已见类别和未见类别统一处理。
- **Seenmask Zero-Shot Network (SZN) **即本文提出的带可见性覆膜的零示例网络。
- **SZN with Perfect Seenmask (SZN-PS) **将可见性覆膜完美化的SZN~~，就是人工标记一个正确的可见性覆膜而不用训练出来的，这个想法非常有趣~~，可以示范可见性覆膜如果能完美的工作的话网络能够达到的一定程度上讲的上限表现。

同时，本文使用一个三元组来进一步表示对于每一次训练的类别划分：


$$
(||train_{seen}||,||train_{unseen}||,||U||)
$$


### 阅读语义分割图像

TODO



## 结果分析：训练方法

### 公共嵌入损失：均方根 VS 余弦

使用FCN-JE VOC (21, 0, 0)来做样例分别使用两个损失函数进行训练，发现无论以损失函数数值还是mIoU值做比较，后者均更快的收敛到一个更好的值，故而本文最终采用余弦损失函数。

### 优化器： SGD VS Adam

同理进行比较，发现后者一样更快、更好，于是本文采用Adam优化器

### 公共嵌入空间的维度

本文考虑的一系列的$j$值：1, 2, 5, 20, 50, 100, 200, 300。发现越大的维度可以利用高纬度的语义嵌入来抓住更多的信号~~（原文用的单词signal，应该是想表达类似于信息的意思）~~

**下方图片页有理解问题！！！**

![ZSSSq]({{ "/ZSSSq.png" | prepend: site.imgrepo }})



## 结果分析：模型准确度

### 语义分割的基线

本文通过在传统语义分割的问题设定下对比FCN-S和FCN-JE，发现两者差距并不大。但通过对比后者相对前者出现问题的地方，本文进一步发现：首先在嵌入空间内，模型能够成功的学习到一定的概念连续性（会在相似类别中分类出错，而不太会偏离到不相关类别中）；其次后者比前者更容易在物体的统一性和平滑性中出问题，进一步体现公共嵌入后用最近邻分类，相对于Softmax分类来讲还有提升的空间；最后公共嵌入空间中的概念连续性也有待于提升。

### 零示例：分析类别密度的影响

为了分析类别密度的影响，本文考察了三个任务：

- 简化数据模型：VOC (9, 2, 10)
- 标准数据模型：VOC (17, 2, 2)
- 拓展数据模型：Context (31, 2, 2)

同时为了方便比较，三者均包含类别“羊”作为测试类别、“火车”作为训练类别/已见类别

#### 简化数据模型

对于FCN-JE，本文发现模型对于已见类别有过拟合而完全不能预测未见类别。~~（这是非常容易遇见的，在不区分已见和未见类别的情况下进行泛化的零示例学习得到的结果通常都是已见类别被过拟合而未见类别有大部分会被误分为已见类别）~~

对于SZN，在已见类别和总体表现中的表现稍优于FCN-JE，而且能够对于未见类别做出分类。而进一步考察分割图片而不是仅仅看数据的话，我们可以看到可见性覆膜已经在进行工作，并且能够将相当一部分未见类别的像素归类为未见。

对于SZN-PS，我们可以发现它相对于SZN的提升不高，说明尽管能够将所有未见像素归类为未见，我们的分类模型依旧会很大概率上将未见类别分类错误，而这可能和简化数据模型中的低类别密度有关~~，说明在这种情况下，可见性覆膜并不是性能提升的瓶颈~~。

进一步分析SZN中的各个类别的错误情况，可以发现错误大多数发生在“概念上连续”的类别中，而且已见类别中的过拟合现象不再发生了~~（咋看出来的？？？因为有已见类别被错分到未见类别了嘛？？？）~~

#### 标准数据模型

大部分的趋势仍然成立：FCN-JE依旧过拟合已见类别，不过它能够对未见类别做出一定的分类了（<0.1%）；在总体表现中SZN仍然比FCN-JE有小幅度的提高，同时在未见类别的表现上，SZN相对FCN-JE有了一个很大程度上的提升，暗示可见性覆膜成功的开始工作的同时，体系中的FCN也能够成功的将未见类别像素映射到公共嵌入空间中的相对正确的位置了。

再看SZN-PS，我们可以发现，它相对于SZN有了极大程度上的提升~~，且进一步看分割图像而不是仅仅看统计数值的话，可以发现在两种情况下被可见性覆膜正确分为未见的像素均有大部分被正确分类了~~，说明可见性覆膜在这种情况下有一定的瓶颈效果了。~~但同时我们也可以发现，即使是SZN-PS，其表现也不佳，说明在其他领域的进一步改进依旧是很有上升空间的。~~

另外，比较可见性覆膜在简化和标准中的表现可以发现，尽管在标准中被分为未见的像素基本上被正确的分类了而在简化中基本没有正确分类，但是在标准中实际上有更少的像素被正确分为未见了。这表明，尽管更高的类别密度有利于未见类别的正确分类，但却会损伤可见性覆膜的正确率，除非同比例的增加$train_{unseen}$集合中的类别密度。

#### 拓展数据模型

同样有许多趋势依旧保持。另外将拓展和标准比较，更能体现同比例增加$train_{unseen}$密度的重要性。

#### 总结类别密度提升的影响

有利于公共嵌入空间中两个嵌入向量对的联结学习，但是不同比例增加$train_{unseen}$的密度的话会损伤可见性覆膜的正确率。



## 总结及未来的工作

三个主要的限制：

1. 高类别密度的数据集是需要的。
2. 可见性覆膜需要更多的训练数据。~~（应该是指$train_{unseen}​$的类别密度）~~
3. 物体内的连续性，相比于语义分割问题更严重。