# 再读Zero-Shot Semantic Segmentation



## 摘要

​	本文提出了一个新的任务：零示例语义分割——为每一个像素点分配一个已见类别或未见类别的标签~~（更确切的说是泛化零示例语义分割）~~。为了完成这一目标，本文提出了“可见性覆膜零示例网络”，它可以在像素级别在公共嵌入的空间内联结编码过的视觉和语义嵌入对。其中“可见性覆膜”是用来判断一个给定的像素属于已见类别还是未见类别。本文的结果可以进一步解释在上文提到的联结过程中高密度的类别对于正确率的重要性。另外，本文还通过设定理想的可见性覆膜~~（就是人工标记可见与未见，这种研究方法还是十分有趣的）~~来研究了这种方法的上限。



## 引入

​	通常，我们的计算机视觉网络是在一些固定的常见类别的标记数据集上进行训练的。由于在一个开放的词库中标记图片是昂贵且不现实的，故而这些类别一定是有限的，于是大多数的事物其实在这个数据集中的捕捉和代表性是很差甚至压根没有的。于是这就激励了对于能识别未见类别的视觉系统的研究。而对于这种零示例学习的研究，很多领先水平的研究都是在试图模仿人类在这个问题上的处理方法——通过转移我们对于其他域内的相似物体或概念的理解来学习或预测未见物体的特点（identity），而这样的尝试，通过从语言领域做转移学习，在图像级别上已经取得了一定的成功。然而在像素级别上的研究却仍然几乎没有。

​	前人的零示例学习的工作已经提出了在公共嵌入空间中联结图像和标签对的方法：视觉和语义模型被训练来尽量将图像和语义对映射到公共嵌入空间中的一个点上。所以解决本文的问题的一个方法就是将这样的视觉模型从图像级别拓展到像素级别，于是其中的主要问题就是怎样发展一个输出像素级别的嵌入，并且同时要考虑到充足的区域性和全局性图像信息的视觉模型。

​	另外，还有一个待解决的问题是：视觉模型中在公共嵌入空间中的已见类别的标签和图像的联结应该在怎样的程度上泛化到未见类别中，如果这样的转移越弱，那么整个模型就会越倾向于简单的将所有像素的类别映射到公共嵌入空间中已见类别的区域中。~~（以上直译，好拗口哦...大致作者想表达的意思应该是一个像素应该怎样才会被判定为未见类别，这是泛化零示例学习一定会面对的问题，因为相对于未见类别，已见类别一定是过拟合的，所以最朴素的解决方案便是要设定一个阈值来判定一个对象是否属于已见类别，而这个阈值不合适便会引起将未见类别分为可见类别或反之的误分类）~~  一个可行的解决方法是提前判断一个像素是否在训练阶段“见过”。于是本文的第二个关键便是构建能在像素级别完成这个任务的“可见性覆膜”。

​	总结来讲，本文的两个关键创新点如下：

 	1. 定义了一个新的任务：零示例语义分割
 	2. 提出了解决这个问题的第一个尝试：带可见性覆膜的零示例网络（SZN）



## 背景和相关工作

### 语义分割

这是现在计算机视觉的一个主要领域之一，FCN现在在这个领域特别成功，本文就使用了FCN作为视觉模型来生成像素级别的视觉嵌入。~~（其实FCN也可以分为两大类，一类是编码解码+跳跃链接型的，另一类是以DeepLab为代表的带孔卷积方法，而本文实际上采用的是前一类）~~

### 零示例学习

零示例学习中的领先的方法是创建一个公共嵌入空间来联结图像-标签对的视觉和语义嵌入信息。以DeViSe为例说明零示例学习的基本过程和损失方程：TODO



## 任务的提出：零示例语义分割

本文采用的数学记号如下：

一个图片/图像`\(I\)`

可见类别集合

不相交的未见类别集合

