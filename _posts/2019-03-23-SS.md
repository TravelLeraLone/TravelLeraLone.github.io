---
layout: post
title: 总结：一些其他比较有趣的语义分割网络
tags: Notes SS NetStruc 总结
categories: Paper
excerpt: 之前比较详细的阅读并分享了一些现在主流的或者基础的语义分割网络结构：FCN、RefineNet、DeepLab等，除此之外还有很多很有趣的针对性解决一些问题的网络结构也比较值得一看。
---

* TOC
{:toc}

之前比较详细的阅读并分享了一些现在主流的或者基础的语义分割网络结构：FCN、RefineNet、DeepLab等，除此之外还有很多很有趣的针对性解决一些问题的网络结构也比较值得一看，故而简略的罗列总结在此：（多是最近新发展的方法，可能时间也是其中一些没有成为主流backbone的原因之一）

---

1. [BiSeNet](https://arxiv.org/pdf/1808.00897v1.pdf)：为了同时保证准确率和时间而提出。

    采用了两条路径，一条快速下采样以取得大的感受野（内容路径），另一条用小的步长来保持空间分辨率（空间路径），随后引入新的特征结合模型将两条路径得到的特征结合。

2. [CCNet](https://arxiv.org/pdf/1811.11721.pdf)：一种巧妙的快速获得全局信息的方法。

    对每个像素两次使用十字交叉操作（即考察十字交叉的路径上的信息）即可使每个像素得到全局信息，使得到全局信息的时间复杂度由边吃的4次方下降到3次方级别。

3. [ESPNet](https://arxiv.org/pdf/1803.06815v2.pdf)：能够保持准确率下降不大的情况下大幅提速的方法。

    理论依据是卷积因数分解理论，将传统卷积分为了两个部分。~~具体的实现方法并没有看懂orz~~

4. [DFN](https://arxiv.org/pdf/1804.09337v1.pdf)：为了解决语义分割时同一物体内的不连续性和不同物体间的低区分度问题。

    相当于在一个传统的U-Net上做了两个改进：1. 解码部分每一次引入Channel Attention Block；2. 编码部分利用每层的信息额外构建一个边界网络用来学习物体的边界，从而提高连续性和区分度。

5. [DANet](https://arxiv.org/pdf/1809.02983.pdf)：引入了注意力机制。

    分别引入了位置注意力和Channel注意力两种机制，最后将两条路线上得到的特征结合。