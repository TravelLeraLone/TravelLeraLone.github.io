---
layout: post
title: Fully Convolutional Networks for Semantic Segmentation
tags: Notes SS NetStruc FL
categories: Paper
excerpt: 语义分割的早期文章，对早期的语义分割方法有了一个比较充分的总结参考后提出了一个当时最佳的方案，同时给出了全卷积网络的思想以及跳跃链接的思想，为之后很多语义分割的工作提供了基础。
---

**原文链接：[Fully Convolutional Networks for Semantic Segmentation (2015)](https://arxiv.org/pdf/1411.4038.pdf)**

# Introduction

核心观点包括：构建一个“fully convolutional”的网络，应用于随意的输入大小并输出一个相对应大小的输出，同时保证高效的推理和学习； noval architecture 以组合deep，coarse层的信息和shallow，fine层的信息用以提高准确率

以前的工作：用convnet给每个pixel label一个类别标签，但有shortcomings

我们的工作：不用pre- and post-processing，用了pre-train model + fine-tunning

下一章讲相关工作，再之后解释FCN的设计和密集预测（dense prediction）tradeoffs，介绍结构，最后是描述实验架构和实验结果

# 相关工作

## fully convolutional networks

## dense prediction with convnets

# Fully convolutional networks

感受野（receptive fields）

通用公式：（适用conv，pooling，non-linearity）


$$
y_{ij} = f_{ks}(\{x_{s_i+\delta_i},s_j+\delta_j\},0\leq\delta_i,\delta_j\leq k) \\
且 f_{ks}og_{k's'} = (fog)_{k'+(k-1)s',ss'}
$$


仅含以上公式层的叫FCNs（其中：k--kernel size；s--stride）

~~再整个loss-function上做SGD和在每个$x_{ij}$的loss-function上做SGD等效~~

## 将分类模型应用到密集预测上

FC可以看作是一个kernel在整个图片的conv，做这样的替换后可以使网络能接受任意大小的输入，并给出一个 classification map。
这样节省了patches之间的重叠部分的重复计算，同时也可以利用the inherent computational efficiency (and aggressive optimization) of convolution then 带来了一个约5倍的加速，both forward和backprop

## 平移和缝合

下采样因子$f$，then原图被平移$f^2$次，每次$(x，y)$其中：$0 < x,y < f$。得到的所有outputs都run through the convnet each。然后做缝合，缝合时每个prediction被放置在其感受野的中心位置。

is another tradeoffs：the filters are prohibited from accessing information at a finer scale than their original design

## 反卷积操作

可以学习是一大优点

## patchwise的训练是对loss的取样

但是并没有发现比FCN好的结果

# Segmentation 结构

## 从分类器到dense FCN

AlexNet、VGGNet-16、GoogLeNet（只用最终的loss function、不用最终的average pooling）

添加1x1的卷积层生成scores，再upsampling

在GoogLeNet上的应用不如其他的效果好

## 核心创新：

skip and combine，changing the line topology into a DAG

本文举例：（也是他们使用的网络）
并不采用最终直接32X upsampling的scores。取而代之的是，先做一个2X upsampling，和之前的倒数第二次pool之后做1x1conv得到的prediction取合，之后做16X upsampling；
继续这样操作：在以上取16X upsampling之前，先做2X upsampling，然后取倒数第三次pooling的结果做1x1 conv得到的prediction取合，再做8X upsampling

在本文的实验中，这样做完后发现mean IU仅增长了0.3相比于上一步，所以作者人文已经饱和（根据IU和视觉的improvement），故而未进一步做下去。

## 实验用架构：

优化：用SGD+动量（0.9）来训练，minibatch of 20 images，fixed learning rates of 1e-3、1e-4和$5^{-5}$，weight decay of $5^{-4}$ or $2^{-4}$，对于bias用双倍learning-rate，zero-initialized，有Dropout。

Fine-tuning：对全部layers做，先做32X再update到16X和8X

Patch Sampling：不用

Class Balancing：不必要（可以通过weighting或sampling the loss）

Dense Prediction：最终的deconv固定为bilinear interpolation，其他的upsampling被初始化为bilinear upsampling

Augmentation：没有优化效果

# 结果

$n_{ij}$ 第i类被分为第j类的像素数；
$n_{cl}$ 总类数；
$t_i$ 第i类总像素数。

则各项指标为：
Pixel accuracy: $\sum_i{n_{ii}} / \sum_i{t_i}$; <br />
Mean accuracy: $(1/n_{cl})\sum_i{n_{ii} / t_i}$; <br />
Mean IU: $(1/n_{cl})\sum_i{(n_{ii} / (t_i + \sum_j{n_{ji}} - n_{ii}))}$; <br />
Frequency weighted IU: $(\sum_k{t_k})^{-1}\sum_i{(t_i n_{ii} / (t_i + \sum_j{n_{ji}} - n_{ii}))}$; 

# 结论

FCN是一个大类模型，现在使用的分类模型只是他的一个特例。